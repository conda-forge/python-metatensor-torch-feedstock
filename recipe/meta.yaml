{% set name = "metatensor-torch" %}
{% set version = "0.7.6" %}

package:
  name: python-{{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/metatensor_torch-{{ version }}.tar.gz
  sha256: bcc23b535e5b86c0d49096cbf73de67141896f4f14c114515d97b936a78353a1

build:
  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 1
  script_env:
    # Don't build metatensor-torch, but use the already compiled `libmetatensor-torch`
    # package
    - METATENSOR_TORCH_PYTHON_USE_EXTERNAL_LIB='ON'

requirements:
  build:
    - python                                 # [build_platform != target_platform]
    - pytorch                                # [build_platform != target_platform]
    - cross-python_{{ target_platform }}     # [build_platform != target_platform]
    # Nothing will be built but we need a correct env to make pip happy
    - {{ compiler('cxx') }}
    - {{ stdlib("c") }}
    - cmake
    - make
  host:
    - python
    - setuptools >=77
    - packaging >=23
    # We build against the CPU version of torch to not have to deal with CUDA compilers
    # (torch's CMake targets tries to find CUDA compilers even when there is no CUDA
    # code to build). This does not impact the `run` dependency, since torch's
    # `run_exports` are variant agnostic
    - libtorch * cpu*
    - pytorch
    - pip
    - libmetatensor-torch {{ version }}
    - python-metatensor-core >=0.1.13,<0.2.0
  run:
    - python
    - pytorch
    - libmetatensor-torch {{ version }}
    - python-metatensor-core >=0.1.13,<0.2.0
    - python-vesin

test:
  imports:
    - metatensor
  commands:
    - pip check
  requires:
    - pip

about:
  home: https://github.com/lab-cosmo/metatensor
  summary: Python bindings for metatensor-torch
  license: BSD-3-Clause
  license_family: BSD
  license_file: LICENSE
  doc_url: docs.metatensor.org

extra:
  recipe-maintainers:
    - HaoZeke
    - PicoCentauri
    - Luthaf
